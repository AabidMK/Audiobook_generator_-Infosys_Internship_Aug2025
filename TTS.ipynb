{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadec51-40dd-4967-9ad8-e847e11a4f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import random\n",
    "from TTS.api import TTS\n",
    "from pydub import AudioSegment\n",
    "\n",
    "MODEL_NAME = \"tts_models/en/vctk/vits\"\n",
    "VOICES = [\"p225\", \"p227\", \"p229\"]\n",
    "\n",
    "def read_markdown_file(file_path: str) -> str:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def split_into_chunks(text: str, max_chars: int = 500):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    chunks = []\n",
    "    buffer = []\n",
    "    length = 0\n",
    "    for s in sentences:\n",
    "        if length + len(s) <= max_chars:\n",
    "            buffer.append(s)\n",
    "            length += len(s)\n",
    "        else:\n",
    "            chunks.append(\" \".join(buffer))\n",
    "            buffer = [s]\n",
    "            length = len(s)\n",
    "    if buffer:\n",
    "        chunks.append(\" \".join(buffer))\n",
    "    return chunks\n",
    "\n",
    "def clean_tags(text: str) -> str:\n",
    "    return re.sub(r'\\[/?voice[^\\]]*\\]', '', text).strip()\n",
    "\n",
    "def synthesize_chunks(chunks, output_path: str):\n",
    "    tts = TTS(MODEL_NAME)\n",
    "    if hasattr(tts, \"speakers\") and tts.speakers:\n",
    "        print(\"Available speakers:\", tts.speakers)\n",
    "    combined = AudioSegment.silent(duration=0)\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        if not chunk.strip():\n",
    "            continue\n",
    "        clean_text = clean_tags(chunk)\n",
    "        voice = random.choice(VOICES)\n",
    "        print(f\"Synthesizing chunk {i}/{len(chunks)} with {voice}\")\n",
    "        wav = tts.tts(text=clean_text, speaker=voice)\n",
    "        segment = AudioSegment(\n",
    "            wav.tobytes(),\n",
    "            frame_rate=tts.synthesizer.output_sample_rate,\n",
    "            sample_width=wav.dtype.itemsize,\n",
    "            channels=1\n",
    "        )\n",
    "        combined += segment\n",
    "    if len(combined) > 0:\n",
    "        combined.export(output_path, format=\"wav\")\n",
    "        print(f\"Audiobook created: {output_path}\")\n",
    "    else:\n",
    "        print(\"No audio generated!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Convert markdown to audiobook\")\n",
    "    parser.add_argument(\"input\", help=\"Input markdown file\")\n",
    "    parser.add_argument(\"-o\", \"--output\", default=\"audiobook.wav\", help=\"Output WAV file\")\n",
    "    args = parser.parse_args()\n",
    "    text = read_markdown_file(args.input)\n",
    "    chunks = split_into_chunks(text)\n",
    "    synthesize_chunks(chunks, args.output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
